apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: nm-vllm
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: huggingface
      version: "1"
      autoSelect: true
      priority: 1
  protocolVersions:
    - v2
    - v1
  containers:
    - name: kserve-container
      image: vllm/vllm-openai:v0.4.2
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
      startupProbe:
        httpGet:
          path: /health
          port: 8000
        failureThreshold: 30
        periodSeconds: 10
      livenessProbe:
        httpGet:
          path: /health
          port: 8000
        failureThreshold: 1
        periodSeconds: 10
