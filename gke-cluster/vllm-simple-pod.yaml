apiVersion: v1
kind: Pod
metadata:
  name: vllm
spec:
  containers:
  - name: vllm
    image: vllm/vllm-openai
    args: ["--model", "microsoft/phi-2", "--tensor-parallel-size", "2", "--dtype", "float16", "--enforce-eager", "--disable-log-requests"]
    resources:
      limits:
        nvidia.com/gpu: 2
    volumeMounts:
      - name: dshm 
        mountPath: "/dev/shm"
  volumes:
  - name: dshm 
    emptyDir:
      medium: Memory
  nodeSelector:
    cloud.google.com/gke-accelerator: nvidia-l4

